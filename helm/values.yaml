# Guide: https://airflow.apache.org/docs/helm-chart/stable/production-guide.html
# Upstream values: https://github.com/apache/airflow/blob/main/chart/values.yaml

airflow:
  defaultAirflowTag: "2.8.4"
  airflowVersion: "2.8.4"

  images:
    airflow:
      repository: finaldie/auto-news
      tag: 0.9.15

    useDefaultImageForMigration: true

  ## secret if use private repository which requires authorization
  #  - secret name: regcred
  #  - secret type: docker
  # registry:
  #   secretName: regcred

  # https://airflow.apache.org/docs/helm-chart/stable/production-guide.html#webserver-secret-key
  # Generated from command: python3 -c 'import secrets; print(secrets.token_hex(16))'
  # Change it if necessary
  webserverSecretKey: bea88c6c0147627c653c54147ea80ab8

  # airflow global affinity
  affinity: {}

  extraEnvFrom: |
    - secretRef:
        name: airflow-secrets

  workers:
    # Notes: by increasing the replicas, need either the storage provider
    # supports ReadWriteMany accessMode OR we have to use the k8s executor
    # and apply affinity rules between tasks to align them in the same
    # pod
    replicas: 1

    resources:
    #   limits:
    #     cpu: 4
    #     memory: 4Gi
      requests:
        cpu: 100m
        memory: 256Mi

    persistence:
      size: 10Gi

    # Increase failureThreshold as we will install the packages
    # from requirements-local.txt, it may take at least 5 minutes
    # Notes: default check interval 60s
    livenessProbe:
      # Default is 5
      failureThreshold: 15

    # Request for data volume
    volumeClaimTemplates:
      - metadata:
          name: airflow-worker-data-pvc
        spec:
          # storageClassName: ""
          accessModes:
            - "ReadWriteOnce"
          resources:
            requests:
              storage: "20Gi"

    # Mount data volume
    extraVolumeMounts:
      - name: airflow-worker-data-pvc
        mountPath: "/opt/airflow/data"

    logGroomerSidecar:
      enabled: true
      retentionDays: 7

    args:
      - "bash"
      - "-c"
      - |-
        echo "User: `id`"
        echo "PWD: `pwd`"
        echo "=================================================="
        echo "Working dir files (tree)"
        echo "=================================================="
        tree
        echo "=================================================="
        echo "Upgrade pip packages from requirements-local.txt  "
        echo "=================================================="
        pip install --upgrade pip
        if [ -f ~/airflow/run/requirements-local.txt ]; then
          echo "[pip] Found requirements-local.txt, installing ..."
          echo "[pip] langchain version (before): `pip list | grep langchain`"
          pip install --upgrade -r ~/airflow/run/requirements-local.txt
          echo "[pip] Installation finished"
          echo "[pip] langchain version (after): `pip list | grep langchain`"
        fi
        echo "=================================================="
        echo "Starting airflow worker ...  "
        echo "=================================================="
        exec \
        airflow {{ semverCompare ">=2.0.0" .Values.airflowVersion | ternary "celery worker" "worker" }}


  triggerer:
    replicas: 1
    persistence:
      size: 5Gi

    resources:
    #   limits:
    #     cpu: 500m
    #     memory: 512Mi
      requests:
        cpu: 100m
        memory: 128Mi

  scheduler:
    replicas: 1
    resources:
      # limits:
      #   cpu: 1
      #   memory: 1Gi
      requests:
        cpu: 100m
        memory: 128Mi

    env:
      - name: "AIRFLOW__SCHEDULER__TASK_QUEUED_TIMEOUT"
        value: "60"
      - name: "AIRFLOW__SCHEDULER__TASK_QUEUED_TIMEOUT_CHECK_INTERVAL"
        value: "15"

  # Default username/pass: admin/admin
  webserver:
    replicas: 1

    resources:
    #  limits:
    #    cpu: 500m
    #    memory: 1Gi
      requests:
        cpu: 100m
        memory: 128Mi

    # If we limited resources, the webserver may not boot up within 60s
    # then it will be killed by k8s, increase the failureThreshold x2,
    # to wait longer time
    startupProbe:
      # Default is 6
      failureThreshold: 12

    env:
      - name: AIRFLOW__WEBSERVER__SHOW_TRIGGER_FORM_IF_NO_PARAMS
        value: "true"

  redis:
    password: bot


#######################################################################
# Redis
#######################################################################
redis:
  enabled: true

  # `standalone` or `replication`
  architecture: standalone

  # Internal use only, no auth
  auth:
    enabled: false

  master:
    persistence:
      enabled: true
      size: 8Gi

    resources:
      # limits:
      #   cpu: 1
      #   memory: 1Gi
      requests:
        cpu: 100m
        memory: 32Mi

    affinity: {}

  metrics:
    enabled: true

    resources:
      requests:
        cpu: 100m
        memory: 32Mi

    # Enable/disable prometheus service monitor
    serviceMonitor:
      enabled: false


#######################################################################
# Milvus
#######################################################################
# upstream values from https://github.com/zilliztech/milvus-helm/blob/master/charts/milvus/values.yaml

milvus:
  enabled: true

  ## Enable or disable Milvus Cluster mode
  cluster:
    enabled: false

  # image:
  #   all:
  #     tag: v2.3.8

  metrics:
    enabled: true

    # enable/disable prometheus service monitor
    serviceMonitor:
      enabled: false

  # global affinity: apply to all components
  affinity: {}

  ######################################################################
  # Milvus components, can be scale out independently
  ######################################################################
  # rootCoordinator:
  #   enabled: true
  #   # You can set the number of replicas greater than 1, only if enable active standby
  #   replicas: 1  # Run Root Coordinator mode with replication disabled
  #
  # queryCoordinator:
  #   enabled: true
  #   # You can set the number of replicas greater than 1, only if enable active standby
  #   replicas: 1  # Run Query Coordinator mode with replication disabled
  #
  # queryNode:
  #   enabled: true
  #   # You can set the number of replicas to -1 to remove the replicas field in case you want to use HPA
  #   replicas: 1
  #
  # indexCoordinator:
  #   enabled: true
  #   # You can set the number of replicas greater than 1, only if enable active standby
  #   replicas: 1   # Run Index Coordinator mode with replication disabled
  #
  # dataCoordinator:
  #   enabled: true
  #   # You can set the number of replicas greater than 1, only if enable active standby
  #   replicas: 1  # Run Data Coordinator mode with replication disabled
  #
  # dataNode:
  #   enabled: true
  #   # You can set the number of replicas to -1 to remove the replicas field in case you want to use HPA
  #   replicas: 1
  #
  # ## mixCoordinator contains all coord
  # ## If you want to use mixcoord, enable this and disable all of other coords
  # mixCoordinator:
  #   enabled: false
  #   # You can set the number of replicas greater than 1, only if enable active standby
  #   replicas: 1 # Run Mixture Coordinator mode with replication disabled


  ######################################################################
  # Milvus Dependencies
  ######################################################################
  ## Milvus UI
  attu:
    enabled: true
    service:
      port: 3001

  ## Milvus backup
  minio:
    enabled: true
    # Default replicas = 4
    replicas: 4
    resources:
      requests:
        cpu: 100m
        # Default is 2Gi, reduce to 256Mi
        memory: 256Mi

    persistence:
      enabled: true
      # Default is 500Gi, reduce to 10Gi
      size: 10Gi

    affinity: {}

  etcd:
    enabled: true
    # Keep in mind, consensus service count must be odd
    replicaCount: 3

    persistence:
      enabled: true
      # Default is 10Gi, reduce to 8Gi
      size: 8Gi

    affinity: {}

  pulsar:
    # Enable it for cluster mode
    enabled: false

    zookeeper:
      # Keep in mind, consensus service count must be odd
      replicaCount: 3

      resources:
        requests:
          # Default is 1Gi, reduce to 256Mi
          memory: 256Mi
          # Default is 0.3cpu, reduce to 0.1
          cpu: 0.1

      volumes:
        # use a persistent volume or emptyDir
        persistence: true
        data:
          name: data
          # Default is 20Gi, reduce to 5Gi
          size: 5Gi

    bookkeeper:
      replicaCount: 3
      volumes:
        journal:
          name: journal
          # Default is 100Gi, reduce to 2Gi
          size: 4Gi
        ledgers:
          name: ledgers
          # Default is 200Gi, reduce to 4Gi
          size: 4Gi
      resources:
        requests:
          # Default is 2Gi, reduce to 256Mi
          memory: 256Mi
          # Default is 1cpu, reduce to 0.2
          cpu: 0.2

    broker:
      replicaCount: 1
      resources:
        requests:
          # Default is 4Gi, reduce to 256Mi
          memory: 256Mi
          # Default is 1.5cpu, reduce to 0.2
          cpu: 0.2

    autorecovery:
      resources:
        requests:
          # Default is 512Mi, reduce to 256Mi
          memory: 256Mi
          # Default is 1cpu, reduce to 0.2
          cpu: 0.2

    proxy:
      replicaCount: 1
      resources:
        requests:
          # Default is 2048Mi, reduce to 256Mi
          memory: 256Mi
          # Default is 1cpu, reduce to 0.2
          cpu: 0.2

#######################################################################
# MySQL
#######################################################################
mysql:
  enabled: true

  # standalone | replication
  architecture: standalone
  auth:
    createDatabase: true
    customPasswordFiles: {}
    database: bot
    defaultAuthenticationPlugin: ''
    existingSecret: ''
    password: 'bot'
    replicationPassword: 'bot'
    replicationUser: bot
    rootPassword: 'bot'
    usePasswordFiles: false
    username: 'bot'

  global:
    imagePullSecrets: []
    imageRegistry: ''
    storageClass: ''

  image:
    debug: false
    digest: ''
    pullPolicy: IfNotPresent
    pullSecrets: []
    registry: docker.io
    repository: bitnami/mysql
    # tag: 8.3-debian-11

  metrics:
    enabled: true

    livenessProbe:
      enabled: true
      failureThreshold: 3
      initialDelaySeconds: 120
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 1
    prometheusRule:
      additionalLabels: {}
      enabled: false
      namespace: ''
      rules: []
    readinessProbe:
      enabled: true
      failureThreshold: 3
      initialDelaySeconds: 30
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 1
    resources:
      limits: {}
      requests: {}
    service:
      annotations:
        prometheus.io/port: '{{ .Values.mysql.metrics.service.port }}'
        prometheus.io/scrape: 'true'
      clusterIP: ''
      port: 9104
      type: ClusterIP

    # enable/disable prometheus service monitor target
    serviceMonitor:
      enabled: false

    persistence:
      accessModes:
        - ReadWriteOnce
      annotations: {}
      enabled: true
      existingClaim: ''
      selector: {}
      size: 4Gi
      storageClass: ''
      subPath: ''
    persistentVolumeClaimRetentionPolicy:
      enabled: false
      whenDeleted: Retain
      whenScaled: Retain
    resources:
      limits: {}
      requests: {}

    service:
      annotations: {}
      clusterIP: ''
      externalTrafficPolicy: Cluster
      extraPorts: []
      headless:
        annotations: {}
      loadBalancerIP: ''
      loadBalancerSourceRanges: []
      nodePorts:
        mysql: ''
      ports:
        mysql: 3306
      sessionAffinity: None
      sessionAffinityConfig: {}
      type: ClusterIP

  # enabled when architecture = replication
  secondary:
    affinity: {}
    persistence:
      accessModes:
        - ReadWriteOnce
      annotations: {}
      enabled: true
      existingClaim: ''
      selector: {}
      size: 4Gi
      storageClass: ''
      subPath: ''
    replicaCount: 2
    resources:
      limits: {}
      requests: {}


#######################################################################
# Adminer
#
# Default values: https://artifacthub.io/packages/helm/cetic/adminer?modal=values
#######################################################################
adminer:
  enabled: true
  affinity: {}
  resources: {}
  service:
    type: ClusterIP
    port: 8080
