diff --git a/src/llm_agent.py b/src/llm_agent.py
index 0c03215..fbec563 100644
--- a/src/llm_agent.py
+++ b/src/llm_agent.py
@@ -362,7 +362,8 @@ class LLMAgentGeneric(LLMAgentBase):
         super().__init__(api_key, model_name)
 
     def init_prompt(self, prompt):
-        self._init_prompt(prompt,strip())
+        self._init_prompt(prompt.strip())
+        return self
 
     def run(self, text: str):
         tokens = self.get_num_tokens(text)
diff --git a/src/llm_prompts.py b/src/llm_prompts.py
index d4c3c92..7bb9708 100644
--- a/src/llm_prompts.py
+++ b/src/llm_prompts.py
@@ -72,10 +72,6 @@ You have a series of random journal notes that need refinement and rewriting wit
 
 Your goal is to:
 - Make the journal entry more cohesive, polished, and organized while preserving the essence of the original content.
-- Have a section for critical insights.
-- Have a section for takeaways.
-- Have a section for action items.
-- Have a section for summary.
 """
 
 # In case need a translation
@@ -103,3 +99,18 @@ LLM_PROMPT_ACTION_ITEM = """
 Analyze the below content carefully and generate concise 'Action Items':
 {content}
 """
+
+LLM_PROMPT_KEY_INSIGHTS = """
+Analyze the below content carefully and generate concise 'Critical Insights':
+{content}
+"""
+
+LLM_PROMPT_TAKEAWAYS = """
+Analyze the below content carefully and generate concise 'Takeaways':
+{content}
+"""
+
+LLM_PROMPT_SUMMARY_SIMPLE = """
+Analyze the below content carefully and generate concise 'Summary':
+{content}
+"""
diff --git a/src/notion.py b/src/notion.py
index 8092be9..da8eacb 100644
--- a/src/notion.py
+++ b/src/notion.py
@@ -1582,7 +1582,7 @@ class NotionAgent:
         print(f"[Notion.createDatabaseItem_ToRead_Journal] title: {page['name']}, page: {page}")
 
         properties, blocks = self._createDatabaseItem_CollectionBase(
-            page["name"], page["source"], [], [], **kwargs)
+            page["title"], page["source"], [], [], **kwargs)
 
         text_blocks = self._createBlock_RichText("paragraph", page["text"])
         blocks.extend(text_blocks)
diff --git a/src/ops_journal.py b/src/ops_journal.py
index 17c21bb..2e32932 100644
--- a/src/ops_journal.py
+++ b/src/ops_journal.py
@@ -41,14 +41,15 @@ class OperatorJournal(OperatorBase):
 
         # 0. Get last_created_time
         client = DBClient()
-        last_created_time = client.get_notion_inbox_created_time(
-            "journal", "default")
+        # last_created_time = client.get_notion_inbox_created_time(
+        #     "journal", "default")
 
-        last_created_time = utils.bytes2str(last_created_time)
-        print(f"Get last_created_time from redis: {last_created_time}")
+        # last_created_time = utils.bytes2str(last_created_time)
+        # print(f"Get last_created_time from redis: {last_created_time}")
 
+        last_created_time = None
         if not last_created_time:
-            last_created_time = (datetime.now() - timedelta(days=365)).isoformat()
+            last_created_time = (datetime.now() - timedelta(days=1)).isoformat()
 
         print(f"last_created_time: {last_created_time}")
 
@@ -112,30 +113,66 @@ class OperatorJournal(OperatorBase):
             last_created_time = page["created_time"]
 
         llm_response = llm_agent.run(content)
+        print(f"Refine content llm response: {llm_response}")
 
-        llm_trans_agent = LLMAgentTranslation()
-        llm_trans_agent.init_prompt()
-        llm_trans_agent.init_llm()
-
-        llm_translation_response = llm_trans_agent.run(llm_response)
-
-        # Generate title and action items
+        # Generate title
         llm_agent_title = LLMAgentGeneric()
         llm_agent_title.init_prompt(llm_prompts.LLM_PROMPT_TITLE)
+        llm_agent_title.init_llm()
+
         title = llm_agent_title.run(llm_response)
         print(f"Journal Title: {title}")
 
+        # Generate insights
+        llm_agent_insights = LLMAgentGeneric()
+        llm_agent_insights.init_prompt(llm_prompts.LLM_PROMPT_KEY_INSIGHTS)
+        llm_agent_insights.init_llm()
+
+        insights = llm_agent_insights.run(llm_response)
+        print(f"Journal insights: {insights}")
+
+        # Generate takeaways
+        llm_agent_takeaways = LLMAgentGeneric()
+        llm_agent_takeaways.init_prompt(llm_prompts.LLM_PROMPT_TAKEAWAYS)
+        llm_agent_takeaways.init_llm()
+
+        takeaways = llm_agent_takeaways.run(llm_response)
+        print(f"Journal takeaways: {takeaways}")
+
+        # Generate action items
         llm_agent_todo = LLMAgentGeneric()
         llm_agent_todo.init_prompt(llm_prompts.LLM_PROMPT_ACTION_ITEM)
+        llm_agent_todo.init_llm()
+
         todo_list = llm_agent_todo.run(llm_response)
         print(f"Journal TODO list: {todo_list}")
 
+        # Generate action items
+        llm_agent_summary = LLMAgentGeneric()
+        llm_agent_summary.init_prompt(llm_prompts.LLM_PROMPT_SUMMARY_SIMPLE)
+        llm_agent_summary.init_llm()
+
+        summary = llm_agent_summary.run(llm_response)
+        print(f"Journal summary: {summary}")
+
+        # Combine all sections together
+        full_content = f"{today} {title}\n\n{llm_response}\n\n{insights}\n\n{takeaways}\n\n{todo_list}\n\n{summary}"
+        print(f"full_content: {full_content}")
+
+        # Generate translation
+        llm_agent_trans = LLMAgentTranslation()
+        llm_agent_trans.init_prompt()
+        llm_agent_trans.init_llm()
+
+        llm_translation_response = llm_agent_trans.run(full_content)
+        print(f"Translation llm response: {llm_translation_response}")
+
         journal_pages = []
         journal_page = {
             "name": f"{today}",
             "source": "Journal",
             "last_created_time": last_created_time,
-            "text": llm_response,
+            "text": full_content,
             "translation": llm_translation_response,
             "title": f"{today} {title}",
             "todo": todo_list or "n/a",
